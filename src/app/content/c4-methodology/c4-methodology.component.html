
<app-headline class="newPageBefore" [headline]="'Methodik'" [h]="1" [number]="'4'" [id]="4"></app-headline>
<p>
  Die Methodik lässt sich für diese Arbeit in fünf Bereiche Aufteilen, welche die einzelnen Unterkapitel darstellen.
</p>
<p>
  Zuerst wird betrachtet wie die die Dauer der Datenaufarbeitung erfasst wird, hier wird neben den Szenarien und Standards auch zwei verschiedene Hardware Ansätze, mobil mit einem Notebook und Stationär mit einer Workstation miteinander vergleichen.
</p>
<p>
  Als nächstes wird auf die Bereitstellung der Datensätze eingegangen, dies soll die Unterschiede der einzelnen Standards hervorheben im bezug auf den Upload zu AWS S3 zur finalen Bereitstellung.
</p>
<p>
  Für den Nutzer der Datensätze ist jedoch die Zeit bis zur Darstellung auf dem Endgerät entscheidend. Denn sollte der Nutzer lange auf seine gewünschten Daten warten müssen wird dieser unter Umständen ungeduldig. Durch die allgemeine Verfügbarkeit und Geschwindigkeit der Geoinformationen von Google Maps (Alphabet Inc.), Bing Maps (Microsoft Corporation) oder ArcGIS Online (ESRI) erwarten Nutzer diese Geschwindigkeiten auch von anderen Anbietern bzw. Diensten.
</p>
<p>
  Für den Betreiber dieser Dienste ist jedoch auch die Betrachtung der monatlichen bzw. jährlichen Kosten relevant. Dabei sind unter anderem nicht nur die Kosten für das eigentliche Hosting zu betrachten sondern auch mögliche Wartungen der Software und anpassungen bei Updates.
</p>
<p>
  Diese gesammelten Daten werden nun in einer gewichteten Matrix abgebildet und jeder Standard erhält eine Punktzahl von 0 bis 9, neben der Punktzahl wird ebenfalls eine Beschreibung und Begründung hinzugefügt um die wahl der Punktzahl zu erläutern. Neben den in Kapitel 4.1 bis 4.4 erfassten Daten werden weitere Kriterien in die Matrix aufgenommen um auch Aspekte wie spezielle Eigenschaften des Standards in diese Matrix einfließen zu lassen.
</p>

  <app-headline [headline]="'Benchmark Datenaufarbeitung'" [h]="2" [number]="'4.1'" [id]="4.1"></app-headline>
  <p>
    Hierbei soll betrachtet werden wie groß der zeitliche Aufwand ist bis die Daten für den Upload aufgearbeitet wurden. Dies Umfasst zum einen die Anzahl der manuellen Arbeitsschritte wie die aufarbeitung der Eingangsdaten sowie die benötigte Rechenzeit der Aufarbeitung dieser Eingangsdaten.
  </p>
  <p>
    Alle Arbeitsschritte wurden sowohl auf einer Workstation sowie auf einem Notebook durchgeführt um die jeweiligen besonderheiten der Hardware in den Daten zu verdeutlichen. Aufgrund der zur verfügung stehenden Hardware wurden alle Benchmarks für die Datenaufarbeitung auf einer 8 Jahre alten Workstation Fujitsu Celsius R670-2 sowie einem 3 Jahre alten ThinkPad X1 Yoga der 3. generation durchgeführt, die relevanten spezifikationen der beiden Computer sind in der nächsten Tabelle zu entnehmen.

  </p>
  <div class="tableWrapper" id="table-2">
    <table>
      <tr>
        <th class="empty"></th>
        <th>Fujitsu Celsius R570-2</th>
        <th>ThinkPad X1 Yoga</th>
      </tr>
      <tr>
        <td class="data meta sameCluster">
          CPU
        </td>
        <td class="data sameCluster">
          2x Intel Xeon X5670
        </td>
        <td class="data sameCluster">
          Intel Core i7-8550U CPU
        </td>
      </tr>
      <tr>
        <td class="data meta sameCluster">
          Basistakt
        </td>
        <td class="data sameCluster">
          2.93 GHz
        </td>
        <td class="data sameCluster">
          1.80 GHz
        </td>
      </tr>
      <tr>
        <td class="data meta sameCluster">
          Boosttakt
        </td>
        <td class="data sameCluster">
          3.33 GHz
        </td>
        <td class="data sameCluster">
          4.00 GHz
        </td>
      </tr>
      <tr>
        <td class="data meta sameCluster">
          Kerne
        </td>
        <td class="data sameCluster">
          2 x 6
        </td>
        <td class="data sameCluster">
          4
        </td>
      </tr>
      <tr>
        <td class="data meta">
          Threads
        </td>
        <td class="data">
          2 x 12
        </td>
        <td class="data">
          8
        </td>
      </tr>
      <tr>
        <td class="data meta sameCluster">
          Arbeitsspeicher
        </td>
        <td class="data sameCluster">

        </td>
        <td class="data sameCluster">

        </td>
      </tr>
      <tr>
        <td class="data meta sameCluster">
          Kapazität
        </td>
        <td class="data sameCluster">
          96 GB
        </td>
        <td class="data sameCluster">
          16 GB
        </td>
      </tr>
      <tr>
        <td class="data meta">
          Physikalischer Takt
        </td>
        <td class="data">
          1333 MHz
        </td>
        <td class="data">
          2133 MHz
        </td>
      </tr>
    </table>
    <p class="caption">Tabelle 2: Relevante Hardwarespezifikationen für GDAL</p>
  </div>
    <p>
      Ubuntu bietet die ohne Installation von weiteren Paketen die Möglichkeit zu erfassen wie lange einzelne Kommandozeilenbefehle dauen. Dies wird einfach durch das hinzufügen von <span class="code">time</span> vor den eigentlichen Befehl ermöglicht. Somit sieht beispielsweise der Befehl zum erstellen eines TMS aus dem Kapitel 3.1 wie folgt aus:
    </p>
    <pre class="code">time gdal2tiles.py --zoom=0-20 -s EPSG:3857 --processes=24 ./Ortho.tif ./Ortho-TMS/</pre>
    <p>
      Zum erfassen der benötigten Zeit wurden alle unnötigen Programme beendet und während der erstellung wurde der Computer nicht für andere Dinge genutzt. Dadurch sollte gewährleistet werden, dass andere nicht Systemrelevanten Programme keine CPU-Leistung nutzen.
    </p>
    <p>
      Sobald die Aufgabe abgeschlossen wurde wird neben der eigentlichen ausgabe des Befehls drei weitere Zeilen mit der benötigten Zeit hinzugefügt, somit sieht die gesamte Ausgabe des oberen Aufrufs wie folgt aus:
    </p>
    <pre class="code">Generating Base Tiles:
0...10...20...30...40...50...60...70...80...90...100
Generating Overview Tiles:
0...10...20...30...40...50...60...70...80...90...100

real	13m15,202s
user	61m12,099s
sys	2m12,649s</pre>
    <p>
      Diese drei Zeitangaben sind komplett unterschiedlicher Natur und bedürfen einer weiteren erklärung<app-quote
      [author]="'stackoverflow - ConcernedOfTunbridgeWells'"
      [lastVisit]="'06.02.2022'"
      [publicationDate]="'25.06.2019'"
      [title]="'Real, User and Sys process time statistics'"
      [vgl]="true"
      [URL]="'https://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1/556411#556411'"></app-quote>:
    </p>
    <ul>
      <li>
        "real" ist die benötigte Realzeit die der Task benötigt hat bis zum Abschluss der Aufgabe.</li>
      <li>
        "user" summiert die CPU-Zeit der einzelnen Threads. Hierdurch ergibt es sich, sofern mehrere Threads diesem Prozess zugewiesen wurden, dass diese Zeitangabe ein vielfaches der Realzeit in Anspruch nimmt.
      </li>
      <li>
        "sys" beschreibt die Zeit die der Prozess für Aufgaben verwendet hat die nur vom Betriebssystem selbst durchgeführt werden können. Dies ist in diesem Beispiel zum Lesen und Schreiben von Dateien der Fall.
      </li>
    </ul>
    <p>
      Durch diese Zeiterfassungsmethode wurden alle erstellten Datensätze erfasst. Um die Vergleichbarkeit zu gewährleisten wurden alle Datensätze 10 mal erstellt. Dies ermöglicht es, einen Durchschnittswert zu ermitteln und somit die Datenqualität zu gewährleisten.
    </p>
    <p>
      Bei Nutzung des Notebooks ist eine extreme CPU-Temeratur von 96 Grad Celsius aufgefallen. Diese hohe Temperatur führte zu dem Problem, dass die CPU nicht mehr den Boosttakt von 4.00 GHz nutzen konnte. Sofern die CPU-Temperatur einen kritischen Wert erreicht versucht das Betriebssystem die CPU durch eine Drosselung des Taktes auf den Basistakt von 1.80 GHz zu schützen. Dies hätte zur Folge, dass die Erstellung der Datensätze um ein wesentliches Länge gedauert hätte.
    </p>
    <p>
      Durch die extrem kompakte Bauform heutiger Notebooks ist dies ein bekanntes Problem und für Thinkpads gibt es eine gut funktionierende Software namens thinkfan<app-quote
      [author]="'ThinkPad-Wiki'"
      [lastVisit]="'06.02.2022'"
      [publicationDate]="'02.09.2020'"
      [title]="'Thinkfan'"
      [vgl]="true"
      [URL]="'https://thinkwiki.de/Thinkfan'"></app-quote>. Diese ermöglicht es die von Ubuntu vordefinierten Temperaturschwellen für das Thinkpad X1 Yoga zu manipulieren um ein einsetzten des CPU-Lüfters bereits bei niedrigeren Temperaturen zu gewährleisten.
    </p>
    <p>
      Eine manipulation der zwei CPU-Lüfter war aufgrund der guten Kühlung der Fujitsu Workstation nicht nötig, die CPUs der Workstation erreichen maximal eine Temperatur von 68 Grad Celsius.
    </p>

  <app-headline [headline]="'Benchmark Datenbereitstellung'" [h]="2" [number]="'4.2'" [id]="4.2"></app-headline>
  <p>
    Durch die verschiedenen Umfänge der Standards in Gesamtspeicherplatz, Datenmenge, Dateigröße ist es erforderlich auch die Dauer der Datenbereitstellung zu betrachten. Dies kann auch ein erheblicher Zeitfaktor bis zur Bereitstellung der Datensätze sein kann.
  </p>
  <p>
    Die Bereitstellung zu S3 erfolg wie im Kapitel <a class="link" href="#content-3.2">3.2 Bereitstellung der Datensätze</a> beschrieben über AWS CLI. Da dies ebenfalls wie GDAL über die Kommandozeile ausgeführt werden kann wird hierfür wie in Kapitel <a class="link" href="#content-4.1">4.1 Benchmark Datenaufarbeitung</a> vor dem eigentlichen Befehl <span class="code">time</span> hinzugefügt um die benötigte Zeit zu erfassen.
  </p>
  <p>
    Bei dem Upload zu AWS S3 ist zu unterscheiden ob eine einzelne Datei hochgeladen werden soll oder der gesamte Inhalt eines Ordners. Für eine einzelne Datei sieht der Aufruf über AWS CLI wie folgt aus:
  </p>
  <pre class="code">time aws s3 cp ./cog/ortho_lindenrain.tif s3://masterarbeit-cog/cog/ortho_lindenrain.tif</pre>
  <p>
    Dies kann für die Standards WMS, WMTS oder COG verwendet werden. Ein TMS hingegen besteht aus zu vielen Dateien um alle einzeln zu nennen, für diesen Standard ist der Upload eines gesamten Ordners zielführend:
  </p>
  <pre class="code">time aws s3 sync ./tms/ortho_lindenrain/ s3://masterarbeit-cog/tms/ortho_lindenrain/</pre>
  <p>
    Da auch hier mehrere Aspekte wie z.B. die Belastung des eigenen Internetanschlusses oder durch Belastung von AWS S3 werden drei Uploads an unterschiedlichen Tagen und Uhrzeiten durchgeführt.
  </p>
  <p>
    Wichtig ist auch die eigene Verbindung innerhalb des Netzwerkes, die Workstation und das Notebook sind durch ein Netzwerkkabel direkt mit dem Router verbunden, eine WLAN-Verbindung könnte zu schwankenden bzw. schlechteren Upload Geschwindigkeiten führen.
  </p>

  <app-headline [headline]="'Kostenfaktor der Bereitstellung'" [h]="2" [number]="'4.3'" [id]="4.3"></app-headline>
  <p>
    Bei den Kosten gibt es drei Bereiche
  </p>
  <ul>
    <li>Kosten für das Hosten der Daten</li>
    <li>Kosten für das Bereitstellen von Rechenkapazitäten</li>
    <li>Kosten für die Installation und Wartung des Geoservers.</li>
  </ul>

  <p>
    Die Kosten für das Hosten von Daten spalten sich ebenfalls auf drei Bereiche auf, das Hinzufügen und Abrufen von Daten sowie das Speichern von Daten.
  </p>
  <p>
    Das Hinzufügen und Abrufen wird per Requests berechnet, es entfallen auf das Hinzufügen pro 1.000 PUT, COPY, POST oder LIST Requests 0,0054 USD. Für das Abrufen entfallen pro 10.000 GET Requests 0.0043 USD.
Das Abrufen der Daten ist jedoch aufgrund der unbekannten Nutzerzahl nur sehr ungenau zu bestimmen. Somit werden hier exemplarische Seitenbesuche betrachtet um eine besser bestimmung der Request-Anzahl zu bestimmen.
  </p>
  <p>
    Das Speichern von Daten wird per Gigabyte pro Monat berechnet. Es gibt zwar eine Preisstaffelung, diese beginnt jedoch erst ab 50 Terabyte und somit weit über den in dieser Arbeit betrachteten Datenmengen. Pro Gigabyte im Monat werden 0,0245 USD berechnet<app-quote
    [author]="'AWS'"
    [lastVisit]="'06.02.2022'"
    [title]="'Amazon S3 – Preise'"
    [vgl]="true"
    [URL]="'https://aws.amazon.com/de/s3/pricing/'"></app-quote>.
  </p>
  <p class="toDo">toDo Kosten EC2</p>
  <p>
    Die Kosten für die Installation und Wartung des Geoservers hängen von den Kapazitäten und Qualifikationen des verfügbaren Personals und somit dem umstand ob dies selbst durchgeführt werden kann oder durch Dienstleister<app-quote
    [author]="'Geoserver'"
    [lastVisit]="'07.02.2022'"
    [title]="'GeoServer Commercial Support'"
    [vgl]="true"
    [URL]="'http://geoserver.org/support/'"></app-quote> erfolgen muss. Für die Kostenbetrachtung werden für das Aufsetzen des Geoservers aufgrund eigener Erfahrungen XXX veranschlagt.
  </p>
  <p>
    Für die Wartung, Monitoring und Updates des Geoservers werden pauschal [toDo: Wie viele Stunden?] angenommen.
  </p>
  <p>
    Unvorhergesehene Ereignisse wie Beispielsweise die Sicherheitslücke log4j, welche auch Geoserver betroffen haben werden hier nicht berücksichtigt.
  </p>

  <app-headline [headline]="'Benchmark Datenabruf'" [h]="2" [number]="'4.4'" [id]="4.4"></app-headline>
  <p class="toDo">toDo</p>

  <app-headline [headline]="'Gewichtete Matrix'" [h]="2" [number]="'4.5'" [id]="4.5"></app-headline>
  <p class="toDo">toDo</p>
